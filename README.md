# StyleCLIP
### Исходные репозитории
[stylegan2-pytorch](https://github.com/rosinality/stylegan2-pytorch)

[encoder4editing](https://github.com/omertov/encoder4editing)

[Оригинальная статья](https://arxiv.org/pdf/2103.17249)

## Обзор

StyleCLIP - это метод для редактирования изображений, который комбинирует возможности генеративной модели StyleGAN2 и мощь языковой модели CLIP от OpenAI. Это позволяет производить редактирование изображений на основе текстовых описаний.

### Основные компоненты

1. **StyleGAN2**: Генеративная сеть, способная создавать высококачественные изображения.
2. **CLIP**: Модель, связывающая изображения и текстовые описания в общем пространстве эмбеддингов.

## Оптимизационный подход

Оптимизационный подход StyleCLIP заключается в нахождении латентного кода, который соответствует заданному текстовому описанию. Основная идея - минимизация разницы между эмбеддингом изображения, генерируемого StyleGAN2, и эмбеддингом текста, получаемого CLIP.

### Шаги оптимизационного подхода

1. **Инициализация**: Начинаем с произвольного или инверсного латентного кода `w` из пространства стилей StyleGAN2.
2. **Генерация изображения**: Используем `w` для генерации изображения с помощью StyleGAN2.
3. **Извлечение эмбеддингов**:
   - Получаем эмбеддинг сгенерированного изображения с помощью CLIP.
   - Получаем эмбеддинг текстового описания с помощью CLIP.
4. **Оптимизация**:
   - Определяем функцию потерь, которая минимизирует разницу между эмбеддингом изображения и эмбеддингом текста.
   - Используем градиентный спуск для обновления латентного кода `w` так, чтобы минимизировать функцию потерь.
5. **Итерация**: Повторяем шаги 2-4 до тех пор, пока функция потерь не достигнет минимума или не будет достигнуто заданное количество итераций.



В данном репозитории приведена реализация StyleCLIP для эдитинга изображений. Реализован оптимизационный подход и инверсия GAN (для эдитинга реальных изображений).

## Начало работы с репозиторием

### Установка виртуального окружения

Для того, чтобы начать работу с репозиторием, необходимо создать виртуальное окружение на Python 3.10 с помощью `venv`.

```bash
# Создание виртуального окружения
python3.10 -m venv styleclip_env

# Активация виртуального окружения
# Для Linux/macOS
source styleclip_env/bin/activate

# Для Windows
styleclip_env\Scripts\activate

# Установка зависимостей
pip install -r requirements.txt
```

### Загрузка весов моделей

Для корректной работы необходимо скачать веса моделей по следующим ссылкам:

- [StyleGAN2](https://drive.google.com/file/d/1igxv6ZP4TFGe_392B-qnSqXnglTKH5yo/view?usp=drive_link)
- [ArcFace модель](https://drive.google.com/file/d/1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn/view)

После загрузки разместите веса в соответствующих директориях в вашем проекте.

### Структура папок
```plaintext
StyleCLIP/
├── encoder4editing/
├── stylegan2-pytorch/
├── .gitignore
├── final_styleclip.ipynb
├── model_ir_se50.pth
├── requirements.txt
└── stylegan2-ffhq-config-f.pt
```